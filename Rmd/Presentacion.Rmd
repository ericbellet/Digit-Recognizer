---
title: "Reconocedor de D√≠gitos Usando SVM"
author: "Eric Bellet, Deyban P√©rez, Leonardo Santella"
date: "14 de mayo de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

####Abstract
El problema de reconocimiento de im√°genes ha sido ampliamente estuidiado por la comunidad cient√≠fica de la computaci√≥n, elaborar modelos que permitan el reconomiento de im√°genes bas√°ndose en conocimiento previo es una de las aplicaciones m√°s poderosas en cuanto al √°rea de la **Inteligencia Artificial** se refiere, ya que su uso puede ir desde reconomiento de rostros, placas, etc. Que automaticen y agilicen el procesamiento y reconocimiento de patrones.

#Introducci√≥n
Ente informe contiene la soluci√≥n elaborada por los integrantes mencionados previamente que cursan la materia de **Miner√≠a de Datos** de la **Universidad Central de Venezuela** dictada por el profesor **Fernando Crema** durante el per√≠odo **02-20015** al problema de reconociento de im√°genes colocado en el sitio web de  [kaggle](https://www.kaggle.com/) utilizando como algoritmo de clasificaci√≥n **M√°quina de Soporte Vectorial** (**SVM**) para clasificar entre un conjunto de im√°genes que contienen ejemplos de n√∫meros escritos a mano que var√≠an en el rango de [0,9].

El objetivo es crear modelos con los diferentes tipos de kernel provistos por el paquete que proporciona el lenguaje **R** en su paquete **e1071** para realizar SVM, analizarlos, compararlos y generar una aplicaci√≥n interactiva que sirva como desmostraci√≥n del trabajo realizado.

#M√°quina de Soporte Vectorial (SVM)

Es una t√©cnica de aprendizaje supervisado que funciona tanto para clasificaci√≥n como para regresi√≥n. Este m√©todo consiste en la b√∫squeda de hiperplanos que **maximicen** la distancia de separaci√≥n entre las diferentes clases presentes mediante la b√∫squeda de vectores de soporte, la idea es maximizar la distancia de proyecci√≥n entre la l√≠nea fontera y los vectores de soporte presentes en el conjutno de datos..  

#An√°lisis del Problema
Se tienen im√°genes de tama√±o **28X28** pixeles, lo que nos da un total de **784 p√≠xeles** que son representado en nuestro **dataset de entrenamiento** por 784 columnas, donde cada columna corresponde a un p√≠xel en el rango **[0,255]** que indica la claridad o la oscuridad del p√≠xel.

El objetivo principal es usar el algoritmo de aprendizaje supervidado de **M√°quina de Soporte Vectorial** para crear modelos (uno por cada kernel provisto por el paquete mencionado anteriormente) y luego compararlos mediante la t√©cnica de evaluaci√≥n de matriz de evaluaci√≥n y as√≠ evaluar su tasa de acierto y fallo.

El problema lo dividimos en tres (3) secciones

* **Preprocesamiento de Par√°metros**: dependiendo del kernel seleccionado, se necesitan ajustar ninguno, uno o varios par√°metros que ayuden a ajustar el modelo hacia una mejor soluci√≥n, en esta secci√≥n se explicar√°n las actividades realizadas y los an√°lisis realizados que se usaron para llevar a cabo la preselecci√≥n de par√°metros para entrenar el modelo.

* **Entrenamiento de los Modelos y Evaluaci√≥n de Modelos**: se describir√° el entrenamiento de los modelos tomando en cuenta los par√°metros obtenidos del paso anterior y luego la correspondiente evaluaci√≥n y comparaci√≥n entre estos.

* **Aplicaci√≥n Interactiva Shiny**: con los modelos entrenados, se cre√≥ una aplicaci√≥n que para una entrada desconocida aplica los modelos entrenados y luego mediante un esquema de votaci√≥n entre la salida de los modelos se emite el juicio final.

Dicho esto, a continuaci√≥n empezaremos a describir las distantas secciones mencionadas previamente.


#Definici√≥n de Funciones a Utilizar

A continuaci√≥n se definen las funciones a utilizar a lo largo del documentos:

1. **install**: funci√≥n que instala un paquete pasado como par√°metro si este no se encuentra instalado. 

```{r}
install = function(pkg)
{
  # If is is installed does not install packages
  if (!require(pkg, character.only = TRUE))
  {
    install.packages(pkg)
    if (!require(pkg, character.only = TRUE))
      stop(paste("load failure:", pkg))
  }
}
```

2. **plotDigit**: funci√≥n que toma como par√°metros la fila y un dataset y genera la gr√°fica del n√∫mero en un formato de 28x28 p√≠xeles. 

```{r}
plotDigit = function(row, dataSet)
{
  image.data = matrix(data.matrix(dataSet[row, 1:ncol(dataSet)]), 28, 28)
  image.data = t(image.data)
  image.data = t(image.data)[ ,nrow(image.data):1]
  image(x = image.data, col = c(0,1))
}
```

3. **sumDiag**: funci√≥n que toma una matriz de confusi√≥n y retorna la suma de la diagonal de dicha matriz de confusi√≥n.

```{r}
sumDiag = function(confusionMatrix)
{
  returnValue = 0
  
  for (i in (1:nrow(confusionMatrix)))
    returnValue = returnValue + confusionMatrix[i,i]
  
  return(returnValue)
}
```

4. **testModel**: funci√≥n que recibe c√≥mo par√°metros un n√∫mero de fila y un dataset, grafica dicho n√∫mero y utiliza los diferentes modelos generados para predecir el ejemplo pasado como par√°metro. Al final entre los cuatro (4) modelos se hace un esquema de votaci√≥n y la respuesta que haya tenido mayor cantidad de votos es la salida que se muestra como soluci√≥n final.

```{r}
testModel = function(row, dataSet)
{
  plotDigit(row, dataSet)
  write(sprintf("Modelo lineal: %s",
                as.matrix(predict(model_linear,
                                  dataSet[row,]))[1][1]),
        stdout())
  
  linear <- as.matrix(predict(model_linear, dataSet[row,]))[1][1]
  
  write(sprintf("Modelo polinomico: %s",
                as.matrix(predict(model_polynomial,
                                  dataSet[row,]))[1][1]),
        stdout())
  
  polynomial <- as.matrix(predict(model_polynomial,
                                  dataSet[row,]))[1][1]
  
  write(sprintf("Modelo radial: %s",
                as.matrix(predict(model_radial,
                                  dataSet[row,]))[1][1]),
        stdout())
  
  radial <- as.matrix(predict(model_radial, dataSet[row,]))[1][1]
  
  write(sprintf("Modelo sigmoid: %s",
                as.matrix(predict(model_sigmoid,
                                  dataSet[row,]))[1][1]),
        stdout())
  
  sigmoid <- as.matrix(predict(model_sigmoid, dataSet[row,]))[1][1]
  
  write(sprintf("Segun el esquema de votacion el numero es: %s",
                names(sort(summary(as.factor(c(linear, polynomial,
                                               radial, sigmoid))),
                           decreasing=T)[1])), stdout())
}
```

#Instalando y Cargando los Paquetes a Utilizar

El paquete **e1071** es el √∫nico paquete externo que se utilizar√°.

```{r}
install("e1071")
library(e1071)
```


#Preprocesamiento de Par√°metros

Comencemos por cargar nuestro dataset de entrenamiento

```{r}
train = read.csv("../data/train.csv")
```

Veamos las dimensiones del dataset de entrenamiento:

```{r}
nrow(train)
ncol(train)
```

Podemos ver que hay 45000 ejemplos de entrenamiento, y 785 columnas de la siguiente forma:

```{r}
train[1,1:4]
```

Donde la primera columna se refiere a la etiqueta de la clase y el restante a los 784 p√≠xeles con valores entre [0, 255] que representan la claridad y oscuridad de cada p√≠xel.

El asunto es el siguiente, tenemos las siguientes f√≥rmulas de los diferentes tipos de kernel:

* **Linear**: u' x v

* **Polynomial**: (gamma x u' x v + coef0) ^ degree

* **Radial**: exp(-gamma x |u - v| ^ 2)

* **Sigmoid**: tanh(gamma x u' x v + coef0)

Donde **u** y **v** son vectores que corresponden a los ejemplos y al vector **theta** que se usa como margen de separaci√≥n pra la divisi√≥n de las clases  respectivamente, al multiplicar estos dos vectores se haya la proyecci√≥n del vector **v** sobre el vector **u**. Y **gamma**, **coef0**, **degree**. Corresponden par√°mettros que deben ir ajust√°ndose para ir entrenar de la mejor manera a nuestro modelo.

La pregunta ahora es: ¬øC√≥mo saber que par√°metros seleccionar?

Las dimensiones del dataset son muy grandes y verlas de una manera gr√°fica no nos podr√° ayudar de mucho. Debido a esto decidimos hacer uso de la siguiente funci√≥n **tune.svm()** esta funci√≥n provista por el paquete **e1071** corre el algoritmo de SVM con diferentes par√°metros y retorna los mejores par√°metros para posteriormente pas√°rselos al algoritmo y poder entrenar el modelo.

El kernel polin√≥mico cuya ecuaci√≥n es: **(gamma x u' x v + coef0) ^ degree** podemos ver que tiene tres (3) par√°metros los cuales se deben ajustar a conveniencia. esto quiere decir que si le pasamos un rango por ejemplo de dos (2) valores a cada uno de ellos supongamos [1,2] para cada uno de ellos, la funci√≥n deber√° entrenar el modelo y hacer las pruebas para **gamma = 1**, **coef0 = 1**, **degree = 1**, luego para **gamma = 1**, **coef0 = 1**, **degree = 2** y as√≠ sucesivamente hasta llegar a: **gamma = 2**, **coef0 = 2**, **degree = 2**. En total se realizar√°n 6 combinaciones y luego se deber√°n comparar los distintos modelos y arrojar como salida los par√°metros que hicieron que el modelo fuera mejor.

Teniendo en cuenta que nuestro conjunto de entrenamiento consta de 45000 ejemplos y que el orden del algoritmo SVM es O(n ^ 3) donde **n** es el tama√±o del dataset de entrenamiento, podemos darnos cuenta de que el algoritmo con 45000 filas tardar√° un tiempo entrenando, ahora imag√≠nense si debe hacerlo seis (6) veces s√≥lo para precalcular los par√°metros. A simple vista nos podemos dar cuenta de que podr√≠an pasar varios d√≠as en el proceso.

Dicho esto para abordar esta problem√°tica, la estrategia utilizada fue hacer un sampling para reducir el n√∫mero de filas a mil (1000) y utilizar ese n√∫mero para precalcular los par√°metros y luego utilizar dichos par√°metros para entrenar los modelos con una mayor cantidad de ejemplos.

```{r}
set.seed(22)
subIndex = sample(nrow(train), 1000, replace = F)
training.data = train[subIndex, ]
```

Convertimos la columna **label** a tipo **factor** porque si est√° est√° en tipo num√©rico el algoritmo entonces har√° regresi√≥n.

```{r}
training.data$label = as.factor(training.data$label)
```

Y ahora precalcularemos los mejores par√°metros para los diferentes modelos:

##Polin√≥mico

```{r}
#parameters_polynomial = tune.svm(label ~ .,
#                                 data = training.data,
#                                 kernel = "polynomial",
#                                 scale = F,
#                                 gamma = 10^(-6:-1),
#                                 cost = 10^(-1:1),
#                                 degree = (2:4),
#                                 coef0 = (-1:1))

#parameters_polynomial$best.model
```

##Radial

```{r}
#parameters_radial = tune.svm(label ~ .,
#                             data = training.data,
#                             kernel = "radial",
#                             scale = F,
#                             gamma = 10^(-6:-1))

#parameters_radial$best.model
```

##Sigmoid

```{r}
#parameters_sigmoid = tune.svm(label ~ .,
#                             data = training.data,
#                              kernel = "sigmoid",
#                              scale = F,
#                              gamma = 10^(-6:-1),
#                              coef0 = (-1:1))

#parameters_sigmoid$best.model
```

Por √∫ltimo salvamos los mejores par√°metros para poder utilizarlos a la hora de entrenar los modelos.

```{r}
#save(parameters_polynomial, file = "parameters/parameters_polynomial.rda")
#save(parameters_radial, file = "parameters/parameters_radial.rda")
#save(parameters_sigmoid, file = "parameters/parameters_sigmoid.rda")
```

Cabe destacar que para el modelo lineal, no hace falta ajustar ning√∫n par√°metro y por eso no se encuentra presente.



#Shiny app
La aplicaciÛn que se desarrollÛ en base a las implementaciones mencionadas anteriormente, b·sicamente permite que el usuario introduzca un n˙mero que indica una fila del dataset **test.csv**, es decir un conjunto de pixeles que representan un n˙mero, una vez introducido el digito se presiona el botÛn **RECONOCER DIGITO** el cual desencadena la ejecuciÛn de una serie de funciones que generan como resultado el reconocimiento de la imagen de cada uno de los kernels, **linear**, **polynomial**, **radial** y **sigmoid**.

##Carga de datos
Se carga el *test.csv* y los distintos modelos que se generaron previamente.
```{r eval=FALSE}
library(shinythemes)
require(shiny)

#WAITING: LOADING test.csv
test = read.csv("data/test.csv")
load(file = "models/model_linear.rda")
load(file = "models/model_polynomial.rda")
load(file = "models/model_radial.rda")
load(file = "models/model_sigmoid.rda")
```
##Interfaz de usuario
En la interfaz de usuario los componentes principales son 4, **numericInput** que solicita que se introduzca la fila que se desea, **actionButton** que ejecuta funciones que se encuentran del lado del servidor, **plotOutput** permite la visualizaciÛn del n˙mero que representa la fila introducida y **verbatimTextOutput** muestra los resultados de reconocimiento de los **diferentes kernels** y el resultado del **esquema de votaciÛn**.
```{r eval=FALSE}
runApp(
  list(
    ui = fluidPage(theme = shinytheme("cerulean"),
      headerPanel('Digit-Recognizer'),
      sidebarPanel(
        numericInput("n", "Introduzca la fila del test.csv:", min = 1, max = nrow(test),value = "Ej: 50"),
        br(),
        actionButton("goButton", "RECONOCER DIGITO", style='float:center;padding:20px; font-size:150%'),br(),
        p("Click en el boton para reconocer el digito"),br(),br(),br(),br(),br(),br(),br(),br(),br(),br()
      ),
      mainPanel(
        plotOutput("plot"),
        h4('Resultados:'),
        verbatimTextOutput("nText"))
        
      ),
```
##Servidor
El servidor utiliza 2 funciones, **plotDigit** y **testModel**.
```{r eval=FALSE}
server = function(input, output) { 
      ntext <- eventReactive(input$goButton, {
        input$n
      })
      
      output$plot <- renderPlot({
        n <- ntext()
        plotDigit(n, test)
      })
      
      output$nText <- renderPrint({
        n <- as.numeric(ntext())
        testModel(n, test)
        
      })
      
      
      
    }
  )
)
```
La funciÛn **plotDigit** permite graficar el n˙mero utilizando el conjunto de pixeles de la fila seleccionada.
```{r eval=FALSE}
plotDigit = function(row, dataSet)
{
  image.data = matrix(data.matrix(dataSet[row, 1:ncol(dataSet)]), 28, 28)
  image.data = t(image.data)
  image.data = t(image.data)[ ,nrow(image.data):1]
  image(x = image.data, col = c(0,1))
}

```
La funciÛn **testModel** muestra el resultado del reconocimiento de la imagen de cada uno de los kernels, y un **esquema de votaciÛn** simple que indica cual es el n˙mero que representa la figura. Se puede desarrollar un **esquema de votaciÛn** m·s completo asign·ndole pesos a los modelos. 
```{r eval=FALSE}
testModel = function(row, dataSet)
{
  
  write(sprintf("Modelo lineal: %s", as.matrix(predict(model_linear, dataSet[row,]))[1][1]), stdout())
  linear <- as.matrix(predict(model_linear, dataSet[row,]))[1][1]
  
  write(sprintf("Modelo polinomico: %s", as.matrix(predict(model_polynomial, dataSet[row,]))[1][1]), stdout())
  polynomial <- as.matrix(predict(model_polynomial, dataSet[row,]))[1][1]
  
  write(sprintf("Modelo radial: %s", as.matrix(predict(model_radial, dataSet[row,]))[1][1]), stdout())
  radial <- as.matrix(predict(model_radial, dataSet[row,]))[1][1]
  
  write(sprintf("Modelo sigmoid: %s", as.matrix(predict(model_sigmoid, dataSet[row,]))[1][1]), stdout())
  sigmoid <- as.matrix(predict(model_sigmoid, dataSet[row,]))[1][1]
  
  write(sprintf("Segun el esquema de votacion el numero es: %s", names(sort(summary(as.factor(c(linear, polynomial, radial, sigmoid))), decreasing=T)[1])), stdout())

  #return(c(linear, polynomial, radial, sigmoid))
  
}
```